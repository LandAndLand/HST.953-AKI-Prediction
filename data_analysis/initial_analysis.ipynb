{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load in data\n",
    "data_path='../data_extraction/data/'\n",
    "cohort = pd.read_table(data_path+'cohort.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               age          los    max_lactate    vaso_frac\n",
      "count  5342.000000  5342.000000    4485.000000  5342.000000\n",
      "mean     71.703842    11.416165     226.160700     0.133613\n",
      "std      48.474031    10.331876   14931.965231     0.214067\n",
      "min      18.138720     3.000300       0.500000     0.000000\n",
      "25%      52.494296     4.790000       1.500000     0.000000\n",
      "50%      65.322301     7.903400       2.200000     0.006947\n",
      "75%      76.984900    14.118000       3.800000     0.196396\n",
      "max     309.777981   173.072500  999999.000000     0.995077\n"
     ]
    }
   ],
   "source": [
    "# numerical variable summaries\n",
    "print cohort[['age','los','max_lactate','vaso_frac']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M    0.510857\n",
      "F    0.489143\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# gender summary\n",
    "print pd.value_counts(cohort['gender'].values,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMERICAN INDIAN/ALASKA NATIVE    0.000374\n",
      "ASIAN                            0.019656\n",
      "BLACK/AFRICAN AMERICAN           0.064770\n",
      "WHITE                            0.727256\n",
      "HISPANIC/LATINO                  0.031636\n",
      "MULTI/OTHER                      0.027331\n",
      "UNKNOWN                          0.128978\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ethnicity summary\n",
    "eth = cohort['ethnicity'].astype('category')\n",
    "\n",
    "# grouping based on the standards at: http://grants.nih.gov/grants/guide/notice-files/NOT-OD-15-089.html\n",
    "eth = eth.cat.add_categories(['HISPANIC/LATINO','MULTI/OTHER','UNKNOWN'])\n",
    "\n",
    "eth[np.array([('HISPANIC' in i or\n",
    "               'PORTUGUESE' in i) for i in eth],dtype=bool)]='HISPANIC/LATINO'\n",
    "eth[np.array([('ASIAN' in i) for i in eth],dtype=bool)]='ASIAN'\n",
    "eth[np.array([('BLACK' in i or\n",
    "               'AFRICAN' in i) for i in eth],dtype=bool)]='BLACK/AFRICAN AMERICAN'\n",
    "eth[np.array([('WHITE' in i or\n",
    "               'MIDDLE EAST' in i) for i in eth],dtype=bool)]='WHITE'\n",
    "eth[np.array([('MULTI' in i or\n",
    "               'OTHER' in i) for i in eth],dtype=bool)]='MULTI/OTHER'\n",
    "eth[np.array([('DECLINE' in i or\n",
    "               'UNABLE' in i or\n",
    "               'UNKNOWN' in i) for i in eth],dtype=bool)]='UNKNOWN'\n",
    "\n",
    "eth = eth.cat.remove_unused_categories()\n",
    "\n",
    "print pd.value_counts(eth.values,normalize=True,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of hours missing MAP values: 0.0729135812521\n"
     ]
    }
   ],
   "source": [
    "# convert raw MAP readings to MAP features\n",
    "# maps = pd.read_csv(data_path+'map.csv')\n",
    "interval = 60\n",
    "\n",
    "# average MAP for every hour\n",
    "maps['hour'] = pd.Series((maps.min_from_intime/interval).astype(int), index=maps.index)\n",
    "\n",
    "# get means for every hour\n",
    "mean_maps = maps.groupby(['icustay_id', 'hour'])['value'].mean()\n",
    "mean_maps = mean_maps.to_frame().reset_index().set_index(['icustay_id'])\n",
    "\n",
    "# interpolate MAPs for missing values\n",
    "min_hours = mean_maps.groupby([mean_maps.index.get_level_values(0)])['hour'].min()\n",
    "max_hours = mean_maps.groupby([mean_maps.index.get_level_values(0)])['hour'].max()\n",
    "\n",
    "interp_index = []\n",
    "for this_icustay in min_hours.index:\n",
    "    min_hour = min_hours.loc[this_icustay]\n",
    "    max_hour = max_hours.loc[this_icustay]\n",
    "    test =[hour for hour in np.arange(min_hour,max_hour+1)]\n",
    "    interp_index += [(this_icustay, hour) for hour in np.arange(min_hour,max_hour+1)]\n",
    "\n",
    "mean_maps = mean_maps.set_index(['hour'],append=True)\n",
    "interp_mean_maps = mean_maps.reindex(pd.MultiIndex.from_tuples(interp_index,names=['icustay_id','hours']))\n",
    "interp_mean_maps = interp_mean_maps['value'].interpolate(method='linear')\n",
    "interp_mean_maps = interp_mean_maps.to_frame().reset_index()\n",
    "\n",
    "# get percent of hours missing a MAP value\n",
    "missing_map = len(interp_mean_maps.index) - len(mean_maps.index)\n",
    "\n",
    "frac_missing = missing_map/float(len(interp_mean_maps.index))\n",
    "print \"Fraction of hours missing MAP values:\", frac_missing\n",
    "\n",
    "# get minimum MAP value per patient\n",
    "min_ind = interp_mean_maps.groupby('icustay_id')['value'].idxmin(skipna=True)\n",
    "min_maps = interp_mean_maps.loc[min_ind]\n",
    "\n",
    "# bin MAP values\n",
    "map_cutoffs = np.append(np.arange(30,100,10),200)\n",
    "interp_mean_maps['bins'] = pd.cut(interp_mean_maps['value'], map_cutoffs)\n",
    "binned_min_maps = pd.cut(min_maps['value'], map_cutoffs)\n",
    "\n",
    "map_fracs = interp_mean_maps.groupby('icustay_id')['bins'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use creatinine measurements to determine AKI onset\n",
    "creatinine = pd.read_csv(data_path+'creatinine.csv')\n",
    "creatinine = creatinine.dropna()\n",
    "\n",
    "# AKIN definition: increase in serum creatinine >= 0.3 mg/dL OR increase of >= 50% in serum creatinine\n",
    "# OR reduction in urine output (<0.5 mL/kg) within 48 hrs\n",
    "time_lim = 48 #hours\n",
    "\n",
    "# calculate time and first creatinine measurement from admission\n",
    "first_creat = creatinine.loc[creatinine.groupby(['icustay_id'])['min_from_intime'].idxmin(skipna=True)]\n",
    "creatinine = creatinine.merge(first_creat,suffixes=('','_first'),on=['icustay_id'],how='left')\n",
    "\n",
    "# get rid of values outside specified time window\n",
    "creatinine = creatinine[(creatinine.min_from_intime_first < creatinine.min_from_intime) \n",
    "                        & (creatinine.min_from_intime < creatinine.min_from_intime_first+time_lim*60)]\n",
    "\n",
    "# get max creatinine value within time window\n",
    "max_creat = creatinine.loc[creatinine.groupby(['icustay_id'])['value'].idxmax(skipna=True)]\n",
    "\n",
    "# nicely summarize creatinine data\n",
    "d = {'icustay_id':max_creat['icustay_id'],\n",
    "     'value_first':max_creat['value_first'],\n",
    "     'value_max':max_creat['value'],}\n",
    "aki_summary = pd.DataFrame(d)\n",
    "\n",
    "# use first and max creatinine within 48 hrs to determine AKI\n",
    "# TODO: incorporate urine information\n",
    "aki_summary['aki'] = ((aki_summary.value_max-aki_summary.value_first>=0.3) | \n",
    "                      (aki_summary.value_max-aki_summary.value_first>=0.5*aki_summary.value_first))\n",
    "aki = aki_summary.set_index('icustay_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_data = cohort[['icustay_id','age','los','max_lactate','vaso_frac','gender']]\n",
    "lr_data['eth'] = eth\n",
    "lr_data = lr_data.set_index('icustay_id')\n",
    "\n",
    "lr_data = lr_data.join(min_maps,how='left')\n",
    "lr_data.rename(columns={'value':'min_map'},inplace=True)\n",
    "\n",
    "lr_data = lr_data.join(aki_summary['aki'],how='inner')\n",
    "lr_data.rename(columns={'value':'aki'},inplace=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
